{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gleened from https://medium.com/@galen.ballew/transferlearning-b65772083b47\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import Sequential\n",
    "import numpy\n",
    "\n",
    "#import inception with pre-trained weights. do not include fully #connected layers\n",
    "VGG16_base = VGG16(weights='imagenet', include_top=False,pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL \n",
    "import os\n",
    "from PIL import Image\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "import random\n",
    "#data = np.random.random((1000, 155,200,3))\n",
    "#labels = np.random.randint(2, size=(1000, numberOfClasses))\n",
    "\n",
    "#VGG16_transfer.fit(data,labels, epochs=4, batch_size=16)\n",
    "    \n",
    "## !! SET THESE PARAMETERS !! ##\n",
    "NumIm = 3000  # The number of images you want\n",
    "Its = 0\n",
    "numD = np.round(NumIm/2)  # Number of daisies\n",
    "\n",
    "\n",
    "data = np.zeros([NumIm,263,320,3])  # Initialize an array for all the data\n",
    "outData= np.zeros([NumIm,512])\n",
    "outLabels=np.zeros([NumIm,2])\n",
    "   \n",
    "\n",
    "# Grab some daisies\n",
    "for file in os.listdir('./daisy'):\n",
    "    if (Its > numD-1):\n",
    "        break\n",
    "    filename = os.fsdecode(file) # Get the file name \n",
    "    \n",
    "    img = image.load_img('./daisy/' + filename, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = VGG16_base.predict(x)\n",
    "    outData[Its,:]=preds[0,:]\n",
    "    outLabels[Its,0]=1\n",
    "    Its += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for file in os.listdir('./roses'):\n",
    "    if (Its > NumIm-1):\n",
    "        break\n",
    "    \n",
    "    filename = os.fsdecode(file) # Get the file name \n",
    "    img = image.load_img('./roses/' + filename, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = VGG16_base.predict(x)\n",
    "    outData[Its,:]=preds[0,:]\n",
    "    outLabels[Its,1]=1\n",
    "    Its += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outData=outData[1:Its-1,:]\n",
    "outLabels=outLabels[1:Its-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"FlowerWeights.csv\",outData)\n",
    "np.savetxt(\"FlowerLabels.csv\",outLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outData= np.loadtxt(\"FlowerWeights.csv\")\n",
    "outLabels= np.loadtxt(\"FlowerLabels.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myPerm= numpy.random.permutation(outData.shape[0])\n",
    "trainSize= round(0.8*outData.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outData=outData[myPerm,:]\n",
    "outLabels=outLabels[myPerm,:]\n",
    "\n",
    "trainData= outData[:trainSize,:]\n",
    "trainLabel= outLabels[:trainSize,:]\n",
    "testData= outData[trainSize:,:]\n",
    "testLabel= outLabels[trainSize:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newModel = Sequential()\n",
    "newModel.add(Dense(256, input_dim=512, activation='relu'))\n",
    "newModel.add(Dense(256, activation='relu'))\n",
    "newModel.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "newModel.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newModel.fit(trainData,trainLabel, nb_epoch=150, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newModel.evaluate(testData,testLabel)[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Getting 99% accuracy on the flower data.\n",
    "Also fast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
