{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================================================\n",
    "# This python notebook will retrain incetion V3 Model, save the weights and make predictions\n",
    "#=======================================================================================================\n",
    "\n",
    "# The directory structure is as follows:\n",
    "#  root\n",
    "#  |\n",
    "#  flowers\n",
    "#  |\n",
    "#  - train\n",
    "#      - roses\n",
    "#      - daisy\n",
    "#  - valid\n",
    "#      - roses\n",
    "#      - daisy    \n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir ='data/flowers/sample/train' #contains two classes cats and dogs\n",
    "validation_data_dir ='data/flowers/sample/valid' #contains two classes cats and dogs\n",
    "\n",
    "nb_train_samples = 10 #1274\n",
    "nb_validation_samples = 50 #1274\n",
    "nb_epoch = 2 # The Number of Epochs to Train over\n",
    "b_size = 5 # The Batch Size\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# and a logistic layer -- let's say we have 2 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('===========================')\n",
    "print('Model Compilation Complete')\n",
    "print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Model Parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now specify the Directories for Training and Validation\n",
    "\n",
    "train_data_dir ='data/flowers/train' #contains two classes cats and dogs\n",
    "validation_data_dir ='data/flowers/valid' #contains two classes cats and dogs\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)#,\n",
    " #       shear_range=0.2,\n",
    " #       zoom_range=0.2,\n",
    " #       horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=b_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=nb_epoch,\n",
    "    samples_per_epoch=128, #128\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples= nb_validation_samples) #1020\n",
    "\n",
    "print('\\n')\n",
    "print('====================================================')\n",
    "print('Training History Model Complete: \\n')\n",
    "print('====================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "N_freeze = 249\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first N_freeze layers and unfreeze the rest:\n",
    "for layer in model.layers[:N_freeze]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[N_freeze:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "#model.fit_generator(...)\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('====================================================')\n",
    "print('Training Complete: \\n')\n",
    "print('====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to an output file for use later\n",
    "\n",
    "model.save(\"inception_retrained_model1\")\n",
    "##################################\n",
    "\n",
    "print('\\n')\n",
    "print('====================================================')\n",
    "print('Saving The Model is Complete: \\n')\n",
    "print('====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the re-trained model\n",
    "from keras.models import load_model\n",
    "\n",
    "retrained_model = load_model('inception_retrained_model1')\n",
    "\n",
    "print('\\n')\n",
    "print('====================================================')\n",
    "print('Loaded in the Retrained Model \\n')\n",
    "print('====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "# Let us use the inception v3 Model\n",
    "img_path = 'roses_1.jpg'\n",
    "#img_path = 'Elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = retrained_model .predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
