{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "#We import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We import the data.\n",
    "\n",
    "VectorizedData= np.load(\"SafetyWeights.npy\")\n",
    "Labels= np.load(\"SafetyLabels.npy\")\n",
    "\n",
    "\n",
    "rebalanceSamples=True\n",
    "if(rebalanceSamples):\n",
    "    locations=[]\n",
    "    fullList=np.zeros(1,dtype=np.int)\n",
    "    shortest= 99999999999999999999;\n",
    "    for k in range(Labels.shape[1]):\n",
    "        locations.append(np.where(Labels[:,k]==1)[0])\n",
    "        shortest=min(shortest,sum(Labels[:,k]==1))\n",
    "    for k in range(Labels.shape[1]):\n",
    "            fullList=  np.concatenate([fullList,np.random.choice(locations[k], shortest,replace=False)] )\n",
    "    fullList=fullList[1:]\n",
    "    VectorizedData=VectorizedData[fullList]\n",
    "    Labels=Labels[fullList]\n",
    "\n",
    "    #We shuffle and cut the data\n",
    "myPerm= np.random.permutation(VectorizedData.shape[0])\n",
    "trainSize= round(0.8*VectorizedData.shape[0])\n",
    "VectorizedData=VectorizedData[myPerm]\n",
    "Labels=Labels[myPerm]\n",
    "\n",
    "#Note: If some sort of under or over sampling was to be\n",
    "#done in order to correct for imbalanced label sets\n",
    "#this is probably the place to do it.\n",
    "trainData= VectorizedData[:trainSize,:]\n",
    "trainLabel= Labels[:trainSize,:]\n",
    "testData= VectorizedData[trainSize:,:]\n",
    "testLabel= Labels[trainSize:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We create a model.\n",
    "\n",
    "#Please note that the model give here is completely Ad Hoc.\n",
    "#There are (hopefully) other models that work better.\n",
    "newModel = Sequential()\n",
    "newModel.add(Dense(4, input_dim=trainData.shape[1], activation='relu'))\n",
    "newModel.add(Dense(testLabel.shape[1], activation='softmax'))\n",
    "\n",
    "newModel.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTrainTime = time.time()\n",
    "newModel.fit(trainData,trainLabel, epochs=1499, batch_size=256)\n",
    "endTime = time.time()\n",
    "print('\\n Time to train = {} s.'.format(endTime - startTrainTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= newModel.predict(testData)[:,1]\n",
    "y_true = testLabel[:,1]\n",
    "\n",
    "y_pred_pos= np.round(y_pred)\n",
    "y_pred_neg= 1-y_pred_pos\n",
    "\n",
    "tp = sum(y_true * y_pred_pos)\n",
    "tn = sum((1-y_true) * y_pred_neg)\n",
    "\n",
    "fp = sum((1-y_true) * y_pred_pos)\n",
    "fn = sum (y_true * y_pred_neg)\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall= tp/(tp+fn)\n",
    "\n",
    "print('Precision:')\n",
    "print(precision)\n",
    "print('\\n Recall:')\n",
    "print(recall)\n",
    "\n",
    "print('\\n Accuracy:')\n",
    "print((tp+tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "iii=0\n",
    "\n",
    "listOfFilenames =[]\n",
    "\n",
    "with open('SafetyFilenames.csv', 'r') as csvfileRead:\n",
    "     spamreader = csv.reader(csvfileRead, delimiter=' ', quotechar='|')\n",
    "     for row in spamreader:\n",
    "        iii=iii+1;\n",
    "        listOfFilenames.append( row[0].replace(',','') )\n",
    "\n",
    "##Note that the \"List of filenames\" is currently in ORIGINAL order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= newModel.predict(VectorizedData)[:,1]\n",
    "\n",
    "listToOutput =['FileName,Danger?,PredictedDanger,MemberOfTestSet?']\n",
    "\n",
    "for iii in range(1, len(myPerm)):\n",
    "    addString= listOfFilenames[myPerm[iii]]\n",
    "    addString=addString+','+str(Labels[iii,1]>0.5)\n",
    "    addString=addString+','+str(y_pred[iii])\n",
    "    addString=addString+','+str(iii>trainSize)\n",
    "    print(addString)\n",
    "    listToOutput.append(addString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SafetyFilenamesWithInfo.csv', 'w', newline='') as myfile:\n",
    "    wr =  csv.writer(myfile, delimiter=';')\n",
    "    wr.writerows(listToOutput)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(myPerm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
